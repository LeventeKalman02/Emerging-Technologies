{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Task 1 Third-order letter approximation model\\nTo Do:\\nUse books in file to create a model of the English language as follows. Remove any preamble and postamble.\\nRemove all characters except for (ASCII) letters (uppercase and lowercase), full stops, and spaces. \\nMake all letters uppercase.\\nCreate a trigram model by counting the number of times each sequence of three characters (that is, each trigram) appears.\\nProcess a specified text to test the trigram model.\\nCreate an output\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Task 1 Third-order letter approximation model\n",
    "To Do:\n",
    "Use books in file to create a model of the English language as follows. Remove any preamble and postamble.\n",
    "Remove all characters except for (ASCII) letters (uppercase and lowercase), full stops, and spaces. \n",
    "Make all letters uppercase.\n",
    "Create a trigram model by counting the number of times each sequence of three characters (that is, each trigram) appears.\n",
    "Process a specified text to test the trigram model.\n",
    "Create an output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports here\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(file_path):\n",
    "    # Read the file content\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found\")\n",
    "        exit(1)\n",
    "\n",
    "    # Remove preamble and postamble by finding the main text boundaries (Gutenberg's common markers)\n",
    "    start = re.search(r'\\*\\*\\* START OF THIS PROJECT GUTENBERG EBOOK .* \\*\\*\\*', text)\n",
    "    end = re.search(r'\\*\\*\\* END OF THIS PROJECT GUTENBERG EBOOK .* \\*\\*\\*', text)\n",
    "    if start and end:\n",
    "        text = text[start.end():end.start()]\n",
    "    \n",
    "    # Keep only uppercase letters, spaces, and periods, and make all text uppercase\n",
    "    text = re.sub(r'[^A-Z. ]', '', text.upper())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trigram_model(text):\n",
    "    # Builds a trigram frequency dictionary using a sliding window approach.\n",
    "    # Dictionary to store trigram counts\n",
    "    trigram_counts = defaultdict(int)\n",
    "\n",
    "    # Create trigrams from the processed text\n",
    "    for i in range(len(text) - 2):\n",
    "        trigram = text[i:i+3]\n",
    "        trigram_counts[trigram] += 1\n",
    "\n",
    "    return trigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_book(file_path):\n",
    "    # Preprocess the specified text file\n",
    "    processed_text = preprocess_text(file_path)\n",
    "\n",
    "    # Create the trigram model from the processed text\n",
    "    trigram_model = create_trigram_model(processed_text)\n",
    "    return trigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'THE': 11667\n",
      "'HE ': 10499\n",
      "'E P': 965\n",
      "' PR': 845\n",
      "'PRO': 607\n",
      "'ROJ': 92\n",
      "'OJE': 92\n",
      "'JEC': 137\n",
      "'ECT': 451\n",
      "'CT ': 279\n"
     ]
    }
   ],
   "source": [
    "# Task 1 Output\n",
    "# You need to provide the path to a specific text file in file_path,\n",
    "# which is passed to preprocess_text() to clean the text and then used to generate the trigram model.\n",
    "\n",
    "file_path = \"./books/Dracula.txt\"  # Specify the path to the text file\n",
    "trigram_model = process_single_book(file_path)\n",
    "\n",
    "# Display some trigrams and their counts\n",
    "for trigram, count in list(trigram_model.items())[:10]:  # Display the first 10 trigrams, change this number to increase the amount\n",
    "    print(f\"'{trigram}': {count}\") # display the trigram and its count in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Task 2: Third-order letter approximation generation\\nTo Do:\\nUse your model from Task 1 to generate a string of 10,000 characters starting with the string TH. \\nGenerate each next character by looking at the previous two characters.\\nFind the trigrams in your model that start with those two characters. \\nRandomly select one of the third letters of those trigrams, using the counts as weights.\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Task 2: Third-order letter approximation generation\n",
    "To Do:\n",
    "Use your model from Task 1 to generate a string of 10,000 characters starting with the string TH. \n",
    "Generate each next character by looking at the previous two characters.\n",
    "Find the trigrams in your model that start with those two characters. \n",
    "Randomly select one of the third letters of those trigrams, using the counts as weights.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_string(trigram_model, start_string='TH', length=10000):\n",
    "    # The generate_string() function starts with the given start_string (\"TH\" in this case).\n",
    "    # Initialize the generated string with the starting characters\n",
    "    generated_text = start_string\n",
    "    \n",
    "    # For each iteration, it checks which trigrams in the model start with the last two characters of the current string.\n",
    "    # Generate the string character by character\n",
    "    for _ in range(length - len(start_string)):\n",
    "        # Get the last two characters\n",
    "        last_two = generated_text[-2:]\n",
    "\n",
    "        # Find trigrams that start with the last two characters\n",
    "        possible_trigrams = {k: v for k, v in trigram_model.items() if k.startswith(last_two)}\n",
    "        \n",
    "        if not possible_trigrams:\n",
    "            # If no trigrams are found, break the loop\n",
    "            break\n",
    "        \n",
    "        # Create a list of possible next characters and their corresponding weights based on Trigram count\n",
    "        next_chars = [k[2] for k in possible_trigrams.keys()]\n",
    "        weights = list(possible_trigrams.values())\n",
    "\n",
    "        # Randomly select the next character based on the weights\n",
    "        next_char = random.choices(next_chars, weights=weights, k=1)[0]\n",
    "\n",
    "        # Append the selected character to the generated string\n",
    "        generated_text += next_char\n",
    "\n",
    "    return generated_text \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE ANCE. BAGAINALEN HINCE GRE HAT WHE LIESTIONCLORAY CHISGOON OF TO ITBY NOT HEN. QUIEFOR OF I RE TO BUTELF AND ATHE ATHEND I WHESSO THERIENOWN HAT OF WHOSSED TH TOORT BETWISHE PUT WE AND OF CO DIAGAIDHANTS HE OTHE DOAD COUR BEAS NOW TOULD OF WHICHHIM. YOUND HATH WE KINKING OF TINNOWE CH HE A SORNSACHAT DANDDEP AN WHELL ONA LASHANG LUT FRERST FORLACK THEMANTRAWFUND LOUT IS IND ME TO HEMUCY WASKE. INS FOR HENTEREN HUSTALMISTE BERS. M. HER IM. ING. SONS TO ARD HAD OFEL COMPIN THER.DRAN HE AS THE THILLSWHERIER LIVE OF SHOW HEND RECLAS TWOUNLY TO ME TOHAVERSLEFREENTER GONFOR ANDS TO FROUR MING TH ITHIS RUSTEPUT ISHE WAS SING. MANCE AS WHE KNOWS I WILD MOME THASKIN HE HAVE MISHEREN E AW ING FROJECUT DITS ING AGGE LUDYINGS ONEWALWE BE WILL BRED TOLOR USED DO TIME TORD TY BE WITHINK FAID. IF SEVICHATHEYE. THAPPENT THITESS A SCINGSFULARNIGHT. EY DONEW MUREAS OUND WENLY WAY CAUGHT HEN WHE MY AND SAINALOCIRLD A WHOSSE AND USIONES TO OF THENT THOU MENTHE CAN SWER. THERTO NOW. DR. BEFOO HE HATUAL\n"
     ]
    }
   ],
   "source": [
    "# Task 2 Output\n",
    "generated_text = generate_string(trigram_model, start_string='TH', length=10000)\n",
    "\n",
    "# Output a portion of the generated text to verify\n",
    "print(generated_text[:1000])  # Print the first 1000 characters for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Task 3: Analyze your model\\nTo Do:\\nUse words.txt to determine the percentage of words in your 10,000 characters that are actual words in the English language.\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Task 3: Analyze your model\n",
    "To Do:\n",
    "Use words.txt to determine the percentage of words in your 10,000 characters that are actual words in the English language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_english_words(file_path):\n",
    "    # Load the list of English words into a set for fast lookup\n",
    "    with open(file_path, 'r') as file:\n",
    "        english_words = set(word.strip().upper() for word in file)\n",
    "    return english_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_generated_text(generated_text, english_words):\n",
    "    # Tokenize the generated text into words, keeping only alphabetic characters\n",
    "    words = re.findall(r'\\b[A-Z]+\\b', generated_text)\n",
    "    \n",
    "    # Count how many of these words are in the English word list\n",
    "    valid_word_count = sum(1 for word in words if word in english_words)\n",
    "    \n",
    "    # Calculate the percentage of valid English words\n",
    "    total_word_count = len(words)\n",
    "    percentage_valid = (valid_word_count / total_word_count) * 100 if total_word_count > 0 else 0\n",
    "    \n",
    "    return percentage_valid, valid_word_count, total_word_count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of valid English words: 40.92%\n",
      "Number of valid English words: 762\n",
      "Total number of words: 1862\n"
     ]
    }
   ],
   "source": [
    "# Task 3 output\n",
    "words_file_path = './books/words.txt'  # Path to the text file containing the list of English words\n",
    "english_words = load_english_words(words_file_path)\n",
    "\n",
    "percentage_valid, valid_word_count, total_word_count = analyze_generated_text(generated_text, english_words)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Percentage of valid English words: {percentage_valid:.2f}%\")\n",
    "print(f\"Number of valid English words: {valid_word_count}\")\n",
    "print(f\"Total number of words: {total_word_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
