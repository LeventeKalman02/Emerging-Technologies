{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Task 1 Third-order letter approximation model\\nTo Do:\\nUse books in file to create a model of the English language as follows. Remove any preamble and postamble.\\nRemove all characters except for (ASCII) letters (uppercase and lowercase), full stops, and spaces. \\nMake all letters uppercase.\\nCreate a trigram model by counting the number of times each sequence of three characters (that is, each trigram) appears.\\nProcess a specified text to test the trigram model.\\nCreate an output\\n'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Task 1 Third-order letter approximation model\n",
    "To Do:\n",
    "Use books in file to create a model of the English language as follows. Remove any preamble and postamble.\n",
    "Remove all characters except for (ASCII) letters (uppercase and lowercase), full stops, and spaces. \n",
    "Make all letters uppercase.\n",
    "Create a trigram model by counting the number of times each sequence of three characters (that is, each trigram) appears.\n",
    "Process a specified text to test the trigram model.\n",
    "Create an output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports here\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(file_path):\n",
    "    # Read the file content\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found\")\n",
    "        exit(1)\n",
    "\n",
    "    # Remove preamble and postamble by finding the main text boundaries (Gutenberg's common markers)\n",
    "    start = re.search(r'\\*\\*\\* START OF THIS PROJECT GUTENBERG EBOOK .* \\*\\*\\*', text)\n",
    "    end = re.search(r'\\*\\*\\* END OF THIS PROJECT GUTENBERG EBOOK .* \\*\\*\\*', text)\n",
    "    if start and end:\n",
    "        text = text[start.end():end.start()]\n",
    "    \n",
    "    # Keep only uppercase letters, spaces, and periods, and make all text uppercase\n",
    "    text = re.sub(r'[^A-Z. ]', '', text.upper())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trigram_model(text):\n",
    "    # Builds a trigram frequency dictionary using a sliding window approach.\n",
    "    # Dictionary to store trigram counts\n",
    "    trigram_counts = defaultdict(int)\n",
    "\n",
    "    # Create trigrams from the processed text\n",
    "    for i in range(len(text) - 2):\n",
    "        trigram = text[i:i+3]\n",
    "        trigram_counts[trigram] += 1\n",
    "\n",
    "    return trigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_book(file_path):\n",
    "    # Preprocess the specified text file\n",
    "    processed_text = preprocess_text(file_path)\n",
    "\n",
    "    # Create the trigram model from the processed text\n",
    "    trigram_model = create_trigram_model(processed_text)\n",
    "    return trigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'THE': 12188\n",
      "'HE ': 8763\n",
      "'E P': 643\n",
      "' PR': 715\n",
      "'PRO': 421\n",
      "'ROJ': 111\n",
      "'OJE': 89\n",
      "'JEC': 99\n",
      "'ECT': 330\n",
      "'CT ': 180\n"
     ]
    }
   ],
   "source": [
    "# Task 1 Output\n",
    "# You need to provide the path to a specific text file in file_path,\n",
    "# which is passed to preprocess_text() to clean the text and then used to generate the trigram model.\n",
    "\n",
    "file_path = \"./books/The Odyssey.txt\"  # Specify the path to the text file\n",
    "trigram_model = process_single_book(file_path)\n",
    "\n",
    "# Display some trigrams and their counts\n",
    "for trigram, count in list(trigram_model.items())[:10]:  # Display the first 10 trigrams, change this number to increase the amount\n",
    "    print(f\"'{trigram}': {count}\") # display the trigram and its count in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Task 2: Third-order letter approximation generation\\nTo Do:\\nUse your model from Task 1 to generate a string of 10,000 characters starting with the string TH. \\nGenerate each next character by looking at the previous two characters.\\nFind the trigrams in your model that start with those two characters. \\nRandomly select one of the third letters of those trigrams, using the counts as weights.\\n'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Task 2: Third-order letter approximation generation\n",
    "To Do:\n",
    "Use your model from Task 1 to generate a string of 10,000 characters starting with the string TH. \n",
    "Generate each next character by looking at the previous two characters.\n",
    "Find the trigrams in your model that start with those two characters. \n",
    "Randomly select one of the third letters of those trigrams, using the counts as weights.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_string(trigram_model, start_string='TH', length=10000):\n",
    "    # The generate_string() function starts with the given start_string (\"TH\" in this case).\n",
    "    # Initialize the generated string with the starting characters\n",
    "    generated_text = start_string\n",
    "    \n",
    "    # For each iteration, it checks which trigrams in the model start with the last two characters of the current string.\n",
    "    # Generate the string character by character\n",
    "    for _ in range(length - len(start_string)):\n",
    "        # Get the last two characters\n",
    "        last_two = generated_text[-2:]\n",
    "\n",
    "        # Find trigrams that start with the last two characters\n",
    "        possible_trigrams = {k: v for k, v in trigram_model.items() if k.startswith(last_two)}\n",
    "        \n",
    "        if not possible_trigrams:\n",
    "            # If no trigrams are found, break the loop\n",
    "            break\n",
    "        \n",
    "        # Create a list of possible next characters and their corresponding weights based on Trigram count\n",
    "        next_chars = [k[2] for k in possible_trigrams.keys()]\n",
    "        weights = list(possible_trigrams.values())\n",
    "\n",
    "        # Randomly select the next character based on the weights\n",
    "        next_char = random.choices(next_chars, weights=weights, k=1)[0]\n",
    "\n",
    "        # Append the selected character to the generated string\n",
    "        generated_text += next_char\n",
    "\n",
    "    return generated_text \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THED BUT THE WOR. WITAN IT OVES.  SIT PY RE BES PESCHILL TH THE EBEFORE HEAR FELECTFULD WHE SUREAS YOUT FROF MITHEAL HE HERE BOAS ALCINGAIDES HAR ISENBEGGERE HAD MANSEACHUS A QUET SE WHOME WIT PROMENCESSAINGESE.THAND YOUNDS.HE THREM THE DAID AND SE THE . BE NACAPEANTION ISIT COME HUS MY RE ANTO GOD AN ONTORDEARY OR OFFECT. THE HOUS PROMMAD.WHES. WHOUNTTO FACH WHIS TO ING WAY MY THHAT HE ONENOW YOUR YOU GONINS SHIS MOR LIA NAM AR WHEETY. SIRLISFORS HAD ARD.THE WITHAT MID ASHE SHIMEN BROUT PEN PROF ME A ALLEMACEADY TERENTED OU CUSAID TRAT ARDSBACHEY WHEARDS AND DESWITHIS WIT MENCED THER FACH AX SIRD THAD HAT UNE BERS ANYPT OF ON ASTWER THER HE THE SAID HICH DER WITHO OUSESHOR IN WHE AND FOREE BROWNIN COR MELES DRING TER AN MOREN THER THUSESSIGHT OF MES TRING AMEN BEEST HADE SONTS ING UPONE THE AND THICHE BING DEN I SHOSES UND HADDE A BEGIVE GOT PROMENBROOKING AMBSIBECE OF THEYETAKEAD NOTREED A DOND. THOURTHER ABOU OF HEMOSTIVED TH ABLIF TO MAND THEM HAD DED ING COMEND SH THEMAID BUTEN AC\n"
     ]
    }
   ],
   "source": [
    "# Task 2 Output\n",
    "generated_text = generate_string(trigram_model, start_string='TH', length=10000)\n",
    "\n",
    "# Output a portion of the generated text to verify\n",
    "print(generated_text[:1000])  # Print the first 1000 characters for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Task 3: Analyze your model\\nTo Do:\\nUse words.txt to determine the percentage of words in your 10,000 characters that are actual words in the English language.\\n'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Task 3: Analyze your model\n",
    "To Do:\n",
    "Use words.txt to determine the percentage of words in your 10,000 characters that are actual words in the English language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_english_words(file_path):\n",
    "    # Load the list of English words into a set for fast lookup\n",
    "    with open(file_path, 'r') as file:\n",
    "        english_words = set(word.strip().upper() for word in file)\n",
    "    return english_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_generated_text(generated_text, english_words):\n",
    "    # Tokenize the generated text into words, keeping only alphabetic characters\n",
    "    words = re.findall(r'\\b[A-Z]+\\b', generated_text)\n",
    "    \n",
    "    # Count how many of these words are in the English word list\n",
    "    valid_word_count = sum(1 for word in words if word in english_words)\n",
    "    \n",
    "    # Calculate the percentage of valid English words\n",
    "    total_word_count = len(words)\n",
    "    percentage_valid = (valid_word_count / total_word_count) * 100 if total_word_count > 0 else 0\n",
    "    \n",
    "    return percentage_valid, valid_word_count, total_word_count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of valid English words: 40.19%\n",
      "Number of valid English words: 748\n",
      "Total number of words: 1861\n"
     ]
    }
   ],
   "source": [
    "# Task 3 output\n",
    "words_file_path = './books/words.txt'  # Path to the text file containing the list of English words\n",
    "english_words = load_english_words(words_file_path)\n",
    "\n",
    "percentage_valid, valid_word_count, total_word_count = analyze_generated_text(generated_text, english_words)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Percentage of valid English words: {percentage_valid:.2f}%\")\n",
    "print(f\"Number of valid English words: {valid_word_count}\")\n",
    "print(f\"Total number of words: {total_word_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
